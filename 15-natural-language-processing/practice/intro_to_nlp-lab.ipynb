{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Natural Language Processing Lab\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab we will further explore sklearn and NLTK's capabilities for processing text. We will use the 20 Newsgroup dataset, which is provided by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting SKLearn dataset and other NLP tools\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use the `fetch_20newsgroups` function to download a training and testing set.\n",
    "\n",
    "Look up the function documentation for how to grab the data.\n",
    "\n",
    "You should pull these categories:\n",
    "- `alt.atheism`\n",
    "- `talk.religion.misc`\n",
    "- `comp.graphics`\n",
    "- `sci.space`\n",
    "\n",
    "Also remove the headers, footers, and quotes using the `remove` keyword argument of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the categories for loading\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"talk.religion.misc\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using function fetch_20newsgroups()\n",
    "data_train = fetch_20newsgroups(subset=\"train\", categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "data_test = fetch_20newsgroups(subset=\"test\", categories=categories, remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 documents\n",
      "4 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"%d documents\" % len(data_train.filenames))\n",
    "print(\"%d categories\" % len(data_train.target_names))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'filenames', 'target_names', 'target', 'DESCR']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data inspection\n",
    "\n",
    "We have downloaded a few newsgroup categories and removed headers, footers and quotes.\n",
    "\n",
    "Because this is an sklearn dataset, it comes with pre-split train and test sets (note we were able to call 'train' and 'test' in subset).\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1. What data taype is `data_train` - It is 'bunch' object file which resembles a dictionary\n",
    "- There are 2034 data points (documents) - approx 508 documents per category\n",
    "- The real data lies in 'data' and 'target' attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "# 'Bunch' object that behaves like extended dictionary\n",
    "print(type(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt.atheism'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category name\n",
    "data_train['target_names'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer index of category\n",
    "data_train['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shmel\\\\scikit_learn_data\\\\20news_home\\\\20news-bydate-train\\\\comp.graphics\\\\38816'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL for document\n",
    "data_train['filenames'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data to machine-learn\n",
    "data_train['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full description of dataset\n",
    "data_train['DESCR'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of data points\n",
    "data_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 target values (alt.atheism, comp.os.ms-windows.misc, comp.graphics etc.)\n",
    "data_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bag of Words model\n",
    "\n",
    "Let's train a model using a simple count vectorizer.\n",
    "\n",
    "1. Initialize a standard CountVectorizer and fit the training data\n",
    "- how big is the feature dictionary?\n",
    "- repeat eliminating english stop words\n",
    "- is the dictionary smaller?\n",
    "- transform the training data using the trained vectorizer\n",
    "- evaluate the performance of a Logistic Regression on the features extracted by the CountVectorizer\n",
    "    - you will have to transform the test_set too. Be carefule to use the trained vectorizer, without re-fitting it\n",
    "\n",
    "**BONUS:**\n",
    "- try a couple modifications:\n",
    "    - restrict the max_features\n",
    "    - change max_df and min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Count Vectorizer and Logistic Regression\n",
    "count_vect = CountVectorizer(stop_words='english', min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "# fit_transform takes in all possible words and returns document-term matrices\n",
    "count_train = count_vect.fit_transform(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 25590)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test set using trained vectorizer (to evaluate it)\n",
    "count_test = count_vect.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(count_train, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pred = logreg.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score from count vectorization: 0.74\n",
      "F1 score from count vectorization: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy score from count vectorization:\", np.round(metrics.accuracy_score(data_test.target, count_pred), 2))\n",
    "print(\"F1 score from count vectorization:\", np.round(metrics.f1_score(data_test.target, count_pred, average='macro'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hashing and TF-IDF\n",
    "\n",
    "Let's see if Hashing or TF-IDF improves the accuracy.\n",
    "\n",
    "1. Initialize a HashingVectorizer and repeat the test with no restriction on the number of features\n",
    "- does the score improve with respect to the count vectorizer?\n",
    "- print out the number of features for this model\n",
    "- Initialize a TF-IDF Vectorizer and repeat the analysis above\n",
    "- print out the number of features for this model\n",
    "\n",
    "**BONUS:**\n",
    "- Change the parameters of either (or both!) models to improve your score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorizer & SGD Classifier\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf_train = tfidf_vect.fit_transform(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test set with trained vectorizer\n",
    "tfidf_test = tfidf_vect.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 26576\n"
     ]
    }
   ],
   "source": [
    "# Number of features extracted from TF-IDF\n",
    "features = tfidf_vect.get_feature_names_out()\n",
    "print(\"Total number of features:\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7812269031781227"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_log = SGDClassifier(loss='log', class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "\n",
    "sgd_log.fit(tfidf_train, data_train.target)\n",
    "\n",
    "sgd_log.score(tfidf_test, data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score from TF-IDF vectorization: 0.78\n",
      "F1 score from TF-IDF vectorization: 0.76\n"
     ]
    }
   ],
   "source": [
    "tfidf_pred = sgd_log.predict(tfidf_test)\n",
    "\n",
    "print(\"Accuracy score from TF-IDF vectorization:\", np.round(metrics.accuracy_score(data_test.target, tfidf_pred), 2))\n",
    "print(\"F1 score from TF-IDF vectorization:\", np.round(metrics.f1_score(data_test.target, tfidf_pred, average='macro'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing vectorizer & SGD Classifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vect = HashingVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "\n",
    "# fit_transform takes in all possible words and returns document-term matrices\n",
    "hash_train = hash_vect.fit_transform(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform test set using trained vectorizer (to evaluate it)\n",
    "hash_test = hash_vect.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CANNOT EXTRACT NUMBER OF FEATURES FROM HASHING - not supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7634885439763488"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "\n",
    "sgd.fit(hash_train, data_train.target)\n",
    "\n",
    "sgd.score(hash_test, data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score from Hashing vectorization: 0.76\n",
      "F1 score from Hashing vectorization: 0.74\n"
     ]
    }
   ],
   "source": [
    "hash_pred = sgd.predict(hash_test)\n",
    "\n",
    "print(\"Accuracy score from Hashing vectorization:\", np.round(metrics.accuracy_score(data_test.target, hash_pred), 2))\n",
    "print(\"F1 score from Hashing vectorization:\", np.round(metrics.f1_score(data_test.target, hash_pred, average='macro'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizers in order of best to worst performance:\n",
    "# TF-IDF, Hashing, Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(max_df=0.25, ngram_range=(1, 2), stop_words='english')), ('sgd', SGDClassifier(class_weight='balanced', loss='log', n_jobs=-1, random_state=42))]\n"
     ]
    }
   ],
   "source": [
    "# Tuning TF-IDF vectorizer with SGD classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')), \n",
    "    ('sgd', SGDClassifier(loss='log', class_weight='balanced', n_jobs=-1, random_state=42))])\n",
    "\n",
    "# max_df values defined as proportions (percentage)\n",
    "parameters = {'tfidf__max_df': (0.25, 0.5, 0.75), \n",
    "              'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search.fit(data_train.data, data_train.target)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train new TF-IDF vectorizer with tuned parameters\n",
    "tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=0.25)\n",
    "\n",
    "# New features matrix for classification tasks\n",
    "X_train_vect = tfidf.fit_transform(data_train.data)\n",
    "\n",
    "# New matrix for testing vectorizer performance\n",
    "X_test_vect = tfidf.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 189472\n"
     ]
    }
   ],
   "source": [
    "# Number of features extracted from TF-IDF\n",
    "tfidf_features = tfidf.get_feature_names_out()\n",
    "print(\"Total number of features:\", len(tfidf_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score from TF-IDF vectorization: 0.77\n"
     ]
    }
   ],
   "source": [
    "sgd.fit(X_train_vect, data_train.target)\n",
    "\n",
    "print(\"Accuracy score from TF-IDF vectorization:\", np.round(sgd.score(tfidf_new, data_test.target), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score from TF-IDF vectorization: 0.75\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test_vect)\n",
    "\n",
    "print(\"F1 score from TF-IDF vectorization:\", np.round(metrics.f1_score(data_test.target, y_pred, average='macro'), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okaay...sgd classifier performance has worsened slightly after tuning but number of features reduced by at least 7000\n",
    "# Other hyperparameters to tune max_features, min_df, "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
