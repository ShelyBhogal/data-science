{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "_Authors: Kevin Markham (Washington, D.C.), Ed Podojil (New York City)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Objectives\n",
    "- Define data modeling and simple linear regression.\n",
    "- Build a linear regression model using a data set that meets the linearity assumption using the scikit-learn library.\n",
    "- Understand and identify multicollinearity in a multiple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is linear regression?\n",
    "\n",
    "Linear regression is a way of modelling some depdendent variable $y$ as a linear combination of one or more independent variables $x$.\n",
    "\n",
    "We are often taught the formula for a straight line is: $y = mx + b$.\n",
    "\n",
    "This can alternatively be written as: $$y = \\beta_{0} + \\beta_{1} x$$\n",
    "\n",
    "### 1.1 What are the independent and dependent variables in this formula?\n",
    "\n",
    "### 1.2 What's the difference between regression and classification?\n",
    "\n",
    "In regression tasks, the **dependent** variable is continuous. In classification tasks, the **dependent** variable is categorical. \n",
    "\n",
    "An example of a regression problem could be: Predicting Google's share price.\n",
    "An example of a classification task could be: Predicting a person's favourite fruit.\n",
    "\n",
    "It's important to note that features in both classification and regression tasks can be a combination of continuous and categorical (we often need to transform categorical features into continuous ones or vice versa depending on the type of model we're using). \n",
    "\n",
    "### Exercise\n",
    "\n",
    "Are the following examples of regression or classification? Remember, when we're deciding whether something is a classification task or a regression task, the **only** thing that matters is whether the **dependent** variable is continuous or categorical. \n",
    "\n",
    "(a) Predicting someone's weight based on their favourite fruit\n",
    "(b) Predicting someone's eye colour based on their weight\n",
    "(c) Predicting which party will have a majority \n",
    "(d) Predicting a party's vote share\n",
    "\n",
    "### 1.3 What do we mean by linear?\n",
    "\n",
    "An equation is **linear** if the highest degree of any of the the independent variables (i.e. $x$) is 1. If there's a term containing $x^2$ for example, the equation is no longer linear because the independent variable is being raised to a power higher than 1. \n",
    "\n",
    "\n",
    "### 1.4 What does 'training' or 'fitting' a linear regression model mean? \n",
    "\n",
    "Linear regression is our first example of supervised learning. In supervised learning tasks, we:\n",
    "\n",
    "1. Obtain a dataset that consists of lots of data points, where each point consists of:\n",
    "\n",
    "    * A value for our label/response/target/dependent variable $y$\n",
    "    * Corresponding values for our features/predictors/independent variables $x$\n",
    "    \n",
    "    You can think of a single 'data point' or 'observation' as corresponding to a single row in a Pandas dataframe\n",
    "    \n",
    "2. Split the dataset into a training set that we'll use to fit or train our model, and a testing set that we'll use to evaluate our model's accuracy. A typical split is 80% of our data will be used for training, and 20% for testing. \n",
    "\n",
    "3. Train or fit our model. This will be different for different models. \n",
    "\n",
    "In linear regression, training is the process of finding the linear equation that best fits our data.\n",
    "\n",
    "In other words, we're finding the $\\beta$ values or **model coefficients** that give us the line of best fit:\n",
    "\n",
    "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
    "- Specifically, we are trying to find the line (mathematically) that minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "- Once we've learned these coefficients, we can use the model to predict the values for $y$, the dependent variable (or 'response') for new data points where we only have access to $x$, the features.\n",
    "\n",
    "![Estimating coefficients](./assets/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line.\n",
    "\n",
    "Evaluation metrics for classification problems, such as accuracy, are not useful for regression problems. We need evaluation metrics designed for comparing continuous values.\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "**Mean absolute error (MAE)** is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean squared error (MSE)** is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root mean squared error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "Let's compare these metrics:\n",
    "\n",
    "- MAE is the easiest to understand, because it's the average error.\n",
    "- MSE is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world. Also, MSE is continuous and differentiable, making it easier to use than MAE for optimization.\n",
    "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are **loss functions**, because we want to minimize them.\n",
    "\n",
    "### 1.5 Why use linear regression?\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain.\n",
    "- Highly interpretable.\n",
    "- Model training and prediction are fast.\n",
    "- No tuning is required (excluding regularization).\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "- Well understood.\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias.\n",
    "- Can't automatically learn feature interactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's try it out\n",
    "\n",
    "Let's work through a simple example 'by hand' to understand how linear regression works. \n",
    "\n",
    "### 2.1 Read in some dummy data\n",
    "\n",
    "Imagine we have a data frame that describes the vote share of the Labour Party vs the percentage of 18-25 year olds in a particular constituency. (Note: this is dummy data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df = pd.DataFrame({'vote_share':[44, 20, 67, 12, 80],'young_population':[24, 8, 28, 7, 35]})\n",
    "votes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Write down the general form of equation we're trying to fit to our data\n",
    "\n",
    "Using the variable names 'vote_share' and 'young_population', write down the general form of linear equation we're trying to fit to our data.\n",
    "\n",
    "What are the values we're trying to find? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Use scikit-learn to fit our model and make predictions\n",
    "\n",
    "This bit is super simple with scikit-learn! We import scikit-learn, initialise the linear regression model, and then fit it to our data:\n",
    "\n",
    "**Step 1:** Import the class you plan to use from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Initialise the model\n",
    "\n",
    "* We've created an object that \"knows\" how to do linear regression, and is just waiting for data.\n",
    "* The ame of the object does not matter.\n",
    "* All parameters not specified are set to their defaults.\n",
    "* We can specify tuning parameters (aka \"hyperparameters\") during this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression() # initialise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Fit the model with data (aka \"model training\").\n",
    "\n",
    "- Model is \"learning\" the relationship between X and y in our \"training data.\"\n",
    "- Process through which learning occurs varies by model.\n",
    "- Occurs in-place.\n",
    "\n",
    "Note that 'X' and 'y' correspond to the correct columns in our 'votes' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = votes_df['vote_share']\n",
    "X = np.array(votes_df['young_population']).reshape(-1, 1)\n",
    "\n",
    "linreg.fit(X, y) # fit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! `linreg` is now a trained model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Inspect our trained model.\n",
    "\n",
    "Now we've fitted our linear regression model, we can look at the coefficients it's learned and evaluate how well the model fits our data using the **sum of squared errors** metric we defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = linreg.coef_\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = linreg.intercept_\n",
    "print(intercept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what the learned coefficient and intercept of our model is, let's write down a formula describing the learned relationship between vote share and young population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = coefficients[0]*X + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the line of best fit against our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X,y_pred,'r',linewidth=0.5)\n",
    "plt.xlabel('Percentage of people aged 18-25')\n",
    "plt.ylabel('Labour vote share')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the intercept ($\\beta_0$):\n",
    "\n",
    "- It is the value of $y$ when all independent variables are 0.\n",
    "- Here, it is the estimated vote share when there are no 18-25 year olds in a constituency.\n",
    "- **Note:** It does not always make sense to interpret the intercept; why? \n",
    "\n",
    "Interpreting the \"youth\" coefficient ($\\beta_1$):\n",
    "\n",
    "- **Interpretation:** An increase of 1% in youth population in a constituency is _associated with_ increasing the Labour vote share by $\\beta_1$\n",
    "- In this case, an increase of 1% in youth population in a constituency is _associated with_ increasing the Labour vote share by 2.3%\n",
    "- This is not a statement of causation.\n",
    "- $\\beta_1$ would be **negative** if an increase in youth population was associated with a **decrease** in Labour vote share.\n",
    "- $\\beta_1$ would be **zero** if youth population is not at all associated with Labour vote share."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** Evaluate our model\n",
    "\n",
    "Exactly how well does our formula, or our 'line of best fit' fit our data?\n",
    "\n",
    "Use our formula for **mean squared error** and **root mean squared error** to calculate this by hand. What's `y_pred` and `y_actual` in this case?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sq_residuals = 0\n",
    "\n",
    "for i in range(0,len(y)):\n",
    "    print(i)\n",
    "    sum_sq_residuals += (y[i]-y_pred[i])**2\n",
    "    \n",
    "print(sum_sq_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sq_residuals/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sum_sq_residuals/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the **mean squared error** and **root mean squared error** using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_actual = y\n",
    "y_pred = y_pred\n",
    "\n",
    "mse = mean_squared_error(y_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Predict the response for a new data point\n",
    "\n",
    "This is the exciting bit! New observations are called \"out-of-sample\" data. Our model uses the information it learned during the model training process.\n",
    "\n",
    "Let's ask the model to make two predictions:\n",
    "\n",
    "* One in a constituency where the youth population is 17%\n",
    "* Another where the youth population is 20%\n",
    "\n",
    "To do this, our feature matrix is always a 2-D array where each row is a list of features. Since we only have a single feature, the youth population, each row will contain only a single value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = [[17], [20]]\n",
    "linreg.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we just predicted using our model is:\n",
    "\n",
    "* In a constituency where the proportion of 18-25 year olds is 17%, the Labour vote share will be around 37%\n",
    "* In a constituency where the proportion of 18-25 year olds is 20%, the Labour vote share will be around 43%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear regression with multiple independent variables\n",
    "\n",
    "Performing linear regression with one independent variable is very straightforward. But most interesting, real life problems will involve many independent variables, not just one! The formula above can be generalised to $n$ independent variables as follows:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n$$\n",
    "\n",
    "- $y$ is the response, or dependent variable\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature).\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature).\n",
    "\n",
    "A practical example of this sort of model applied to our vote share example might be:\n",
    "\n",
    "$vote\\:share = \\beta_0 + \\beta_1*young\\:population + \\beta_2*home\\:ownership + \\beta_3*unemployment\\:rate$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple linear regression with the 2016 US Presidential Election dataset\n",
    "\n",
    "Now let's try this method out with a much bigger dataset! Read in the dataset, which describes the Trump vote share for every county in the US for the 2016 US Presidential elections, together with demographic information for each county. \n",
    "\n",
    "We'll be using this dataset to investigate which demographic factors are the biggest drivers of Trump support, and ultimately predict vote share in new, out-of-sample counties.\n",
    "\n",
    "### 3.1 Read in the training data\n",
    "\n",
    "This consists of data for 80% of the counties in the US. The remaining 20% of counties will be our testing dataset; we won't read that in yet!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('./data/us_presidential_votes_clean.csv')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the data dictionary, which is in the `data` folder under the filename `us_presidential_votes_dictionary.csv`\n",
    "\n",
    "Familiarise yourself with the contents of the file.\n",
    "\n",
    "* What does each row correspond to?\n",
    "\n",
    "* What's the column name of the indepependent variable?\n",
    "\n",
    "* What are the column names of our dependent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Inspect the data\n",
    "\n",
    "Use `sns.pairplot`, `sns.heatmap`, `describe` and `corr` to:\n",
    "\n",
    "(a) Create a pairplot of all different pairings of variables in our dataset (this might take a while depending on how fast your laptop is!)\n",
    "(b) Generate a correlation matrix\n",
    "(c) Visualise the correlation matrix with a heatmap\n",
    "\n",
    "Then, by visual inspection, discuss the following questions on your tables:\n",
    "\n",
    "(a) Which variables look like they're most strongly associated or correlated with Trump support?\n",
    "\n",
    "(b) Do the associations make intuitive sense? If not, why not? \n",
    "\n",
    "(c) Do some of the associations look like they describe causal relationships? Which ones? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(training_data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fit a linear regression model with just ONE independent variable \n",
    "\n",
    "Using your exploratory data analysis above, pick **one** independent variable that you think is strongly associated with Trump support. Enter the column name of that feature here, as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'White'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the column name of our dependent variable here, as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_name = 'Trump'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a linear regression model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_model = LinearRegression() # initialise \n",
    "\n",
    "X_train = np.array(training_data[feature_name]).reshape(-1, 1)\n",
    "y_train = training_data[response_name]\n",
    "\n",
    "trump_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the coefficient and intercept of the learned model, and plot the actual values of your dependent vs independent variable against the line of best fit, as in our dummy example above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = trump_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = trump_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these values compute y_pred, which is the line of best fit for our data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model = coefficients[0]*X_train + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot our data against the line of best fit- don't forget to add labels for the x and y axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_train,y_train,alpha=0.3)\n",
    "plt.plot(X_train,y_model,'r',linewidth=0.5)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the mean squared error of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_train, y_model)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On your table, discuss which feature you chose and why, and compare root mean squared errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Test our simple linear model on out of sample data\n",
    "\n",
    "Now we've trained our simple linear model, we can read in our testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = pd.read_csv('./data/us_presidential_votes_test.csv')\n",
    "testing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our model to predict Trump vote share in these new counties, based on our chosen independent variable for those counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = testing_data['Trump']\n",
    "X_test = np.array(testing_data[feature_name]).reshape(-1, 1)\n",
    "\n",
    "y_pred = trump_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our test data against our line of best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test,y_test,alpha=0.3)\n",
    "plt.plot(X_test,y_pred,'r',linewidth=0.5)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the accuracy of our model on unseen data, using root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple linear regression\n",
    "\n",
    "Now let's build a more complex model, using **all** available features to predict the strength of the Trump vote. Fill in the cells below to do this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by intialising a linear regression model; call it `trump_model_multi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_model_multi = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the features and response for our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(training_data.drop(columns='Trump')) # extract an array of features from our election_df dataframe\n",
    "y_train = training_data['Trump'] # extract the corresponding values of the Trump vote \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the model to this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_model_multi.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the coefficients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_model_multi.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_model_multi.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this model to predict Trump support in our out-of-sample counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(testing_data.drop(columns='Trump'))\n",
    "y_test = testing_data['Trump']\n",
    "\n",
    "y_pred = trump_model_multi.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the root mean squared error of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean squared error: %f'% mse)\n",
    "print('Root mean squared error: %f'% rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does adding more features improve model performance compared to our simple linear regression model? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
